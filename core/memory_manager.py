"""
ä¸‰å±¤è¨˜æ†¶ç®¡ç†ç³»çµ±
- Instant Memory: ç•¶å‰å°è©±ä¸Šä¸‹æ–‡ï¼ˆRAMï¼‰
- Short-term Memory: è¿‘æœŸç¶“é©—å’Œå­¸ç¿’ï¼ˆå¯åºåˆ—åŒ–ï¼‰
- Long-term Memory: æ°¸ä¹…çŸ¥è­˜åº«ï¼ˆæŒä¹…åŒ–å­˜å„²ï¼‰
"""

import os
import json
import pickle
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
from collections import deque
import hashlib


class MemoryEntry:
    """è¨˜æ†¶æ¢ç›®åŸºé¡"""
    
    def __init__(self, content: Any, metadata: Optional[Dict] = None):
        self.content = content
        self.metadata = metadata or {}
        self.timestamp = datetime.now()
        self.access_count = 0
        self.last_access = self.timestamp
        self.importance = 1.0  # 0-1 ä¹‹é–“
        
        # ç”Ÿæˆå”¯ä¸€ ID
        self.id = self._generate_id()
    
    def _generate_id(self) -> str:
        """ç”ŸæˆåŸºæ–¼å…§å®¹çš„å”¯ä¸€ ID"""
        content_str = str(self.content) + str(self.timestamp)
        return hashlib.md5(content_str.encode()).hexdigest()[:16]
    
    def access(self):
        """è¨˜éŒ„è¨ªå•"""
        self.access_count += 1
        self.last_access = datetime.now()
    
    def boost_importance(self, amount: float = 0.1):
        """æå‡é‡è¦æ€§"""
        self.importance = min(1.0, self.importance + amount)
    
    def decay_importance(self, amount: float = 0.05):
        """é™ä½é‡è¦æ€§"""
        self.importance = max(0.0, self.importance - amount)
    
    def to_dict(self) -> Dict:
        """åºåˆ—åŒ–"""
        return {
            "id": self.id,
            "content": self.content,
            "metadata": self.metadata,
            "timestamp": self.timestamp.isoformat(),
            "access_count": self.access_count,
            "last_access": self.last_access.isoformat(),
            "importance": self.importance
        }
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'MemoryEntry':
        """ååºåˆ—åŒ–"""
        entry = cls(data["content"], data.get("metadata"))
        entry.id = data["id"]
        entry.timestamp = datetime.fromisoformat(data["timestamp"])
        entry.access_count = data["access_count"]
        entry.last_access = datetime.fromisoformat(data["last_access"])
        entry.importance = data["importance"]
        return entry


class InstantMemory:
    """å³æ™‚è¨˜æ†¶ - ç•¶å‰å°è©±ä¸Šä¸‹æ–‡"""
    
    def __init__(self, max_entries: int = 50):
        self.max_entries = max_entries
        self.entries: deque = deque(maxlen=max_entries)
        self.context: Dict[str, Any] = {}
    
    def add(self, content: Any, metadata: Optional[Dict] = None):
        """æ·»åŠ è¨˜æ†¶æ¢ç›®"""
        entry = MemoryEntry(content, metadata)
        self.entries.append(entry)
    
    def get_recent(self, n: int = 10) -> List[MemoryEntry]:
        """ç²å–æœ€è¿‘ n æ¢è¨˜æ†¶"""
        return list(self.entries)[-n:]
    
    def search(self, query: str) -> List[MemoryEntry]:
        """ç°¡å–®æœç´¢"""
        results = []
        query_lower = query.lower()
        
        for entry in self.entries:
            if query_lower in str(entry.content).lower():
                entry.access()
                results.append(entry)
        
        return results
    
    def set_context(self, key: str, value: Any):
        """è¨­ç½®ä¸Šä¸‹æ–‡è®Šé‡"""
        self.context[key] = value
    
    def get_context(self, key: str, default: Any = None) -> Any:
        """ç²å–ä¸Šä¸‹æ–‡è®Šé‡"""
        return self.context.get(key, default)
    
    def clear(self):
        """æ¸…ç©ºå³æ™‚è¨˜æ†¶"""
        self.entries.clear()
        self.context.clear()
    
    def get_summary(self) -> str:
        """ç”Ÿæˆè¨˜æ†¶æ‘˜è¦"""
        if not self.entries:
            return "No recent memories"
        
        recent = self.get_recent(5)
        summary_parts = []
        
        for entry in recent:
            content_preview = str(entry.content)[:100]
            summary_parts.append(f"- {content_preview}...")
        
        return "\n".join(summary_parts)


class ShortTermMemory:
    """çŸ­æœŸè¨˜æ†¶ - è¿‘æœŸç¶“é©—å’Œå­¸ç¿’"""
    
    def __init__(self, storage_path: Path, max_entries: int = 500, retention_days: int = 30):
        self.storage_path = storage_path
        self.max_entries = max_entries
        self.retention_days = retention_days
        self.entries: List[MemoryEntry] = []
        
        # å‰µå»ºå­˜å„²ç›®éŒ„
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        # åŠ è¼‰ç¾æœ‰è¨˜æ†¶
        self._load()
    
    def add(self, content: Any, metadata: Optional[Dict] = None, importance: float = 0.5):
        """æ·»åŠ çŸ­æœŸè¨˜æ†¶"""
        entry = MemoryEntry(content, metadata)
        entry.importance = importance
        self.entries.append(entry)
        
        # è‡ªå‹•æ¸…ç†
        self._cleanup()
    
    def search(self, query: str, top_k: int = 10) -> List[MemoryEntry]:
        """æœç´¢ç›¸é—œè¨˜æ†¶"""
        results = []
        query_lower = query.lower()
        
        for entry in self.entries:
            # ç°¡å–®çš„é—œéµè©åŒ¹é…
            content_str = str(entry.content).lower()
            if query_lower in content_str:
                entry.access()
                results.append((entry, entry.importance * (1 + entry.access_count * 0.1)))
        
        # æŒ‰ç›¸é—œæ€§æ’åº
        results.sort(key=lambda x: x[1], reverse=True)
        
        return [entry for entry, _ in results[:top_k]]
    
    def get_important(self, threshold: float = 0.7, top_k: int = 20) -> List[MemoryEntry]:
        """ç²å–é‡è¦è¨˜æ†¶"""
        important = [e for e in self.entries if e.importance >= threshold]
        important.sort(key=lambda x: x.importance, reverse=True)
        return important[:top_k]
    
    def decay_old_memories(self):
        """è¡°æ¸›èˆŠè¨˜æ†¶çš„é‡è¦æ€§"""
        now = datetime.now()
        
        for entry in self.entries:
            age_days = (now - entry.timestamp).days
            if age_days > 7:
                decay_rate = 0.02 * (age_days - 7)
                entry.decay_importance(decay_rate)
    
    def _cleanup(self):
        """æ¸…ç†éæœŸå’Œä¸é‡è¦çš„è¨˜æ†¶"""
        now = datetime.now()
        retention_threshold = now - timedelta(days=self.retention_days)
        
        # ç§»é™¤éæœŸè¨˜æ†¶
        self.entries = [
            e for e in self.entries
            if e.timestamp > retention_threshold or e.importance > 0.8
        ]
        
        # å¦‚æœè¶…éå®¹é‡ï¼Œç§»é™¤æœ€ä¸é‡è¦çš„
        if len(self.entries) > self.max_entries:
            self.entries.sort(key=lambda x: x.importance, reverse=True)
            self.entries = self.entries[:self.max_entries]
    
    def save(self):
        """ä¿å­˜åˆ°ç£ç›¤"""
        save_file = self.storage_path / "short_term_memory.json"
        
        data = {
            "version": "1.0",
            "timestamp": datetime.now().isoformat(),
            "entries": [e.to_dict() for e in self.entries]
        }
        
        with open(save_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def _load(self):
        """å¾ç£ç›¤åŠ è¼‰"""
        save_file = self.storage_path / "short_term_memory.json"
        
        if not save_file.exists():
            return
        
        try:
            with open(save_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.entries = [MemoryEntry.from_dict(e) for e in data.get("entries", [])]
            
            # åŠ è¼‰å¾Œæ¸…ç†
            self._cleanup()
        except Exception as e:
            print(f"âš ï¸  åŠ è¼‰çŸ­æœŸè¨˜æ†¶å¤±æ•—: {e}")


class LongTermMemory:
    """é•·æœŸè¨˜æ†¶ - æ°¸ä¹…çŸ¥è­˜åº«"""
    
    def __init__(self, storage_path: Path):
        self.storage_path = storage_path
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        # çŸ¥è­˜åˆ†é¡
        self.categories = {
            "skills": [],      # å­¸åˆ°çš„æŠ€èƒ½
            "knowledge": [],   # çŸ¥è­˜æ¢ç›®
            "experiences": [], # ç¶“é©—æ•™è¨“
            "optimizations": [], # ä»£ç¢¼å„ªåŒ–
            "failures": [],    # å¤±æ•—è¨˜éŒ„
            "successes": []    # æˆåŠŸæ¡ˆä¾‹
        }
        
        self._load()
    
    def add(self, content: Any, category: str = "knowledge", metadata: Optional[Dict] = None):
        """æ·»åŠ é•·æœŸè¨˜æ†¶"""
        if category not in self.categories:
            category = "knowledge"
        
        entry = MemoryEntry(content, metadata)
        entry.importance = 1.0  # é•·æœŸè¨˜æ†¶é è¨­é‡è¦
        
        self.categories[category].append(entry)
    
    def search(self, query: str, category: Optional[str] = None, top_k: int = 10) -> List[Tuple[str, MemoryEntry]]:
        """æœç´¢çŸ¥è­˜åº«"""
        results = []
        query_lower = query.lower()
        
        # é¸æ“‡æœç´¢ç¯„åœ
        if category and category in self.categories:
            search_categories = {category: self.categories[category]}
        else:
            search_categories = self.categories
        
        # æœç´¢
        for cat_name, entries in search_categories.items():
            for entry in entries:
                content_str = str(entry.content).lower()
                if query_lower in content_str:
                    entry.access()
                    score = entry.importance * (1 + entry.access_count * 0.1)
                    results.append((cat_name, entry, score))
        
        # æ’åº
        results.sort(key=lambda x: x[2], reverse=True)
        
        return [(cat, entry) for cat, entry, _ in results[:top_k]]
    
    def get_category(self, category: str) -> List[MemoryEntry]:
        """ç²å–ç‰¹å®šåˆ†é¡çš„æ‰€æœ‰è¨˜æ†¶"""
        return self.categories.get(category, [])
    
    def get_all_categories(self) -> Dict[str, int]:
        """ç²å–æ‰€æœ‰åˆ†é¡åŠå…¶æ•¸é‡"""
        return {cat: len(entries) for cat, entries in self.categories.items()}
    
    def save(self):
        """ä¿å­˜åˆ°ç£ç›¤"""
        save_file = self.storage_path / "long_term_memory.json"
        
        data = {
            "version": "1.0",
            "timestamp": datetime.now().isoformat(),
            "categories": {
                cat: [e.to_dict() for e in entries]
                for cat, entries in self.categories.items()
            }
        }
        
        with open(save_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def _load(self):
        """å¾ç£ç›¤åŠ è¼‰"""
        save_file = self.storage_path / "long_term_memory.json"
        
        if not save_file.exists():
            return
        
        try:
            with open(save_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            for cat, entries in data.get("categories", {}).items():
                if cat in self.categories:
                    self.categories[cat] = [MemoryEntry.from_dict(e) for e in entries]
        except Exception as e:
            print(f"âš ï¸  åŠ è¼‰é•·æœŸè¨˜æ†¶å¤±æ•—: {e}")


class MemoryManager:
    """çµ±ä¸€è¨˜æ†¶ç®¡ç†å™¨"""
    
    def __init__(self, memory_root: Path):
        self.memory_root = memory_root
        
        # åˆå§‹åŒ–ä¸‰å±¤è¨˜æ†¶
        self.instant = InstantMemory()
        self.short_term = ShortTermMemory(memory_root / "short_term_memory")
        self.long_term = LongTermMemory(memory_root / "long_term_memory")
        
        print("âœ… è¨˜æ†¶ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
        self._print_stats()
    
    def remember(self, content: Any, importance: float = 0.5, metadata: Optional[Dict] = None):
        """æ™ºèƒ½è¨˜æ†¶ï¼šæ ¹æ“šé‡è¦æ€§è‡ªå‹•åˆ†å±¤"""
        # ç¸½æ˜¯æ·»åŠ åˆ°å³æ™‚è¨˜æ†¶
        self.instant.add(content, metadata)
        
        # ä¸­ç­‰ä»¥ä¸Šé‡è¦æ€§ï¼šæ·»åŠ åˆ°çŸ­æœŸè¨˜æ†¶
        if importance >= 0.5:
            self.short_term.add(content, metadata, importance)
        
        # é«˜é‡è¦æ€§ï¼šæ·»åŠ åˆ°é•·æœŸè¨˜æ†¶
        if importance >= 0.8:
            category = metadata.get("category", "knowledge") if metadata else "knowledge"
            self.long_term.add(content, category, metadata)
    
    def recall(self, query: str, include_instant: bool = True, include_short: bool = True, 
               include_long: bool = True) -> Dict[str, List]:
        """å…¨å±€æª¢ç´¢è¨˜æ†¶"""
        results = {
            "instant": [],
            "short_term": [],
            "long_term": []
        }
        
        if include_instant:
            results["instant"] = self.instant.search(query)
        
        if include_short:
            results["short_term"] = self.short_term.search(query)
        
        if include_long:
            long_results = self.long_term.search(query)
            results["long_term"] = [entry for _, entry in long_results]
        
        return results
    
    def consolidate_memories(self):
        """è¨˜æ†¶æ•´åˆï¼šå°‡é‡è¦çš„çŸ­æœŸè¨˜æ†¶æå‡åˆ°é•·æœŸè¨˜æ†¶"""
        important_short = self.short_term.get_important(threshold=0.85)
        
        promoted_count = 0
        for entry in important_short:
            # æ ¹æ“šå…ƒæ•¸æ“šç¢ºå®šåˆ†é¡
            category = entry.metadata.get("category", "experiences")
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = self.long_term.search(str(entry.content)[:50], category=category, top_k=1)
            if not existing:
                self.long_term.add(entry.content, category, entry.metadata)
                promoted_count += 1
        
        if promoted_count > 0:
            print(f"âœ… æ•´åˆè¨˜æ†¶ï¼š{promoted_count} æ¢çŸ­æœŸè¨˜æ†¶æå‡åˆ°é•·æœŸè¨˜æ†¶")
        
        return promoted_count
    
    def save_all(self):
        """ä¿å­˜æ‰€æœ‰è¨˜æ†¶"""
        self.short_term.save()
        self.long_term.save()
        print("ğŸ’¾ æ‰€æœ‰è¨˜æ†¶å·²ä¿å­˜")
    
    def _print_stats(self):
        """æ‰“å°è¨˜æ†¶çµ±è¨ˆ"""
        print(f"  å³æ™‚è¨˜æ†¶: {len(self.instant.entries)} æ¢")
        print(f"  çŸ­æœŸè¨˜æ†¶: {len(self.short_term.entries)} æ¢")
        
        long_stats = self.long_term.get_all_categories()
        total_long = sum(long_stats.values())
        print(f"  é•·æœŸè¨˜æ†¶: {total_long} æ¢")
        for cat, count in long_stats.items():
            if count > 0:
                print(f"    - {cat}: {count}")


# æ¸¬è©¦ä»£ç¢¼
if __name__ == "__main__":
    print("ğŸ§  æ¸¬è©¦è¨˜æ†¶ç®¡ç†ç³»çµ±\n")
    
    # åˆå§‹åŒ–
    memory_root = Path("C:/Users/YourUser/YK/memory")  # è«‹ä¿®æ”¹è·¯å¾‘
    manager = MemoryManager(memory_root)
    
    # æ¸¬è©¦è¨˜æ†¶æ·»åŠ 
    print("\nğŸ“ æ¸¬è©¦ 1: æ·»åŠ ä¸åŒé‡è¦æ€§çš„è¨˜æ†¶")
    manager.remember("å­¸ç¿’äº†å¦‚ä½•ä½¿ç”¨ pytest", importance=0.3, metadata={"type": "learning"})
    manager.remember("æˆåŠŸå„ªåŒ–äº†æ¨ç†é€Ÿåº¦ï¼Œæå‡ 40%", importance=0.9, 
                     metadata={"category": "optimizations", "improvement": 0.4})
    manager.remember("Gemini API èª¿ç”¨å¤±æ•—æ™‚è¦åˆ‡æ›åˆ°æœ¬åœ°æ¨¡å‹", importance=0.95,
                     metadata={"category": "experiences", "type": "failure_handling"})
    
    # æ¸¬è©¦æª¢ç´¢
    print("\nğŸ” æ¸¬è©¦ 2: æª¢ç´¢è¨˜æ†¶")
    results = manager.recall("å„ªåŒ–")
    for layer, entries in results.items():
        if entries:
            print(f"\n  {layer}: æ‰¾åˆ° {len(entries)} æ¢")
            for entry in entries[:2]:
                print(f"    - {str(entry.content)[:60]}")
    
    # æ¸¬è©¦æ•´åˆ
    print("\nğŸ”„ æ¸¬è©¦ 3: è¨˜æ†¶æ•´åˆ")
    manager.consolidate_memories()
    
    # ä¿å­˜
    print("\nğŸ’¾ æ¸¬è©¦ 4: ä¿å­˜è¨˜æ†¶")
    manager.save_all()
    
    print("\nâœ… æ¸¬è©¦å®Œæˆï¼")
